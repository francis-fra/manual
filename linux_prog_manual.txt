#------------------------------------------------------------
# Postgresql
#------------------------------------------------------------
# login as user postgres:
sudo -u postgres bash

# login as postgres and start psql client
sudo -u postgres psql postgres

# start postgres client
# default database is the same as username
psql
psql -U <username> -d <database>

#--------------------------------------------------------------------
# admin
#--------------------------------------------------------------------
# create user login (at bash)
createuser --interactive fra

# create new user with password
createuser -P fra
# alternatively,
postgres=# CREATE USER yourname WITH SUPERUSER PASSWORD 'yourpassword';

# create new database
createdb ucidb
# alternatively,
<user>=# CREATE DATABASE <dbname> WITH OWNER = <ownerName>;

# grant permission to create db
<user>=# ALTER USE <user> CREATEDB;
# grant permission
<user>=# GRANT <privilege> TO <user>;

#--------------------------------------------------------------------
# commands:
#--------------------------------------------------------------------
# list all tables
\dt
# connect to database <db>
\c db
# show schema
\d+ <tablename>

# list all users:
<user>=# \du

# set user password
<user>=# \password <user>

# run query at terminal, e.g.
psql -d ucidb -c "select * from abalone limit 10"


--------------------------------------------------------------------
# import csv file to postgressql database
--------------------------------------------------------------------
# create table schema
csvsql abalone.csv > maketable.sql
psql -d <dbname> < maketable.sql

# load data (type inside cli)
\copy <table name> FROM <csv file>  CSV HEADER;

# export table to
\copy customers TO '/tmp/customers.csv' CSV HEADER;

--------------------------------------------------------------------
# extension
--------------------------------------------------------------------
SELECT name, default_version, installed_version, left(comment,30) As comment
FROM pg_available_extensions
WHERE installed_version IS NOT NULL
ORDER BY name;

# to install extension:
# download extension file, then
CREATE EXTENSION <extension>, e.g:
CREATE EXTENSION fuzzystrmatch;


#------------------------------------------------------------
# Docker
#------------------------------------------------------------
# start
docker run -h <host_name> -it <docker_image>

# check image
docker inspect <image_name>

# check running docker
docker ps
docker ps -a

# to remove docker image from local
docker rm <image_name>

# log
docker logs <image_name>

# to save image
docker commit cowsay test/cowsayimage



#------------------------------------------------------------
# CLI Data Science installation
#------------------------------------------------------------
# installation
pip install csvkit
sudo npm install xml2json-command

sudo apt-get install jq

# install json2csv
# no sudo, user based (need golang)
go get github.com/jehiah/json2csv

#------------------------------------------------------------
# Data Science Command Line
#------------------------------------------------------------
cat hello-world | wc -w
< hello-world wc -w

# convert xlsx to csv
in2csv <excel input file> > <csv out file>

# quick look at csv file
cat imdb-250.csv | head -n 10 | csvcut -c Title,Year | csvlook


# download file with curl
curl <url>
# ftp with login credentials
curl -u username:password ftp://host/file

# translate fro lower to upper
echo "hi" | tr '[:lower:]' '[:upper:]'


# TODO: getopts
# word count and sort by frequency
cat shakes.txt | tr '[:upper:]' '[:lower:]' | grep -oE '\w+' | sort | uniq -c | sort -nr | head -n 10


# python / R command line
#! /usr/bin/env python
#! /usr/bin/env Rscript

# header / body / cols

# get the header of a csv file
< tips.csv header

# remove the header
< tips.csv header -d 

# add a header
< tips.csv header -a newheader

# use 'tr' to transform text, but apply to the 'body' only and only to
# the 'day' col only
< tips.csv cols -c day body "tr '[a-z]' '[A-Z]'" | head -n 5 | csvlook

# csvcut
# select all cols except species
< iris.csv csvcut -C species | head -n 5 | csvlook

# csvsql
< iris.csv csvsql --query "SELECT sepal_length, petal_length FROM stdin WHERE sepal_length > 6" | head -n 5 | csvlook

# filtering - csvgrep
# sel size with is 5
csvgrep -c size -r "5" tips.csv | csvlook


# create new cols -- transformation
< names.csv csvsql --query "SELECT id, first_name || ' ' || last_name AS full_name, born FROM stdin" | csvlook

# stack csv (vertical)
csvstack Iris-*.csv 

# horizontal stack of the three files: bills.csv, customers.csv and datetime.csv
paste -d, {bills,customers,datetime}.csv

# inner join
csvjoin -c species iris.csv irismeta.csv | csvcut -c sepal_length,sepal_width,species,usda_id | csvlook

# csvsql
csvsql --query 'SELECT i.sepal_length, i.sepal_width, i.species, m.usda_id FROM iris i JOIN irismeta m ON (i.species = m.species)' iris.csv irismeta.csv | csvlook

#---------------------------------------------------------------------
# Data Science Tools
#---------------------------------------------------------------------
# login name
whoami
# host name
hostname
# current date
date

# data structure
tree 

# which json2csv
home/fra/Project/GoProj/bin/json2csv

# word count
wc -l xxx.csv

# view files
head / less / more / tail


# set an executable python script
# put this at the first line
#!/usr/bin/env python

# set an executable R script
# put this at the first line
#!/usr/bin/env Rscript


# convert excel file to csv file
in2csv xxx.xlsx > xxx.csv

# to quickly view xlsx file
in2csv xxx.xlsx | head | csvcut -c <column names> | csvlook
in2csv xxx.xlsx --sheet <sheet name> | head | csvcut -c <column names> | csvlook

# download from the web
curl -s <url> -o out_file
curl -u username:password ftp://host/file

# word count
cat shakes.txt | tr '[:upper:]' '[:lower:]' | grep -oE '\w+' | sort |
uniq -c | sort -nr | head -n 10

# random sample with specified rate (e.g. 10%)
sample -r 10%

# replace values
tr <original_value> <new_value>
# e.g. echo 'hello world!' | tr ' ' '_'

# delete characters
echo 'hello world!' | tr -d -c '[a-z]'

# munipulate adder
# e.g. to add a header
seq 5 | header -a count

# to extract header
cat tips.csv | header
< tips.csv header

# to delete header
cat tips.csv header -d | head

# apply a certain command only to the body
body
# apply a certain command only to some columns
cols

e.g. change the column 'day' to uppercase
< tips.csv cols -c day body "tr '[a-z]' '[A-Z]'" | head


# do sql query on csv
seq 5 | header -a value | csvsql --query "SELECT SUM(value) AS sum FROM stdin"


# convert XML (HTML) to json
< table.html xml2json > table.json
< table.json jq '.' | head -n 25

# jq : extract and reshape json data
# e.g. take the values and give them labels
< table.json jq -c '.html.body.tr[] | {country: .td[1][],border:'\ '.td[2][], surface: .td[3][]}' > countries.json

# convert json to csv
< countries.json json2csv -p -k border,surface > countries.csv

#---------------------------------------------------------------------------------
# CSV scrub operations
#---------------------------------------------------------------------------------
# extract and reordering
< iris.csv csvcut -c sepal_length,petal_length,sepal_width,petal_width | head | csvlook

# select columns
< tips.csv csvcut -c bill,tip
# select columns and save the results
< tips.csv csvcut -c day,time | tee datetime.csv | head -n 3 | csvlook
< tips.csv csvcut -c sex,smoker,size | tee customers.csv | head -n 3 | csvlook

# exclude species
< iris.csv csvcut -C species | head -n 5 | csvlook

# Filtering
# exclude size with values 1 to 4
csvgrep -c size -i -r "[1-4]" tips.csv | csvlook

#---------------------------------------------------------------------------------
# csvsql
#---------------------------------------------------------------------------------
< iris.csv csvsql --query "SELECT sepal_length, petal_length, sepal_width, petal_width FROM stdin" | head -n 5 | csvlook

< tips.csv csvsql --query "SELECT * FROM stdin WHERE bill > 40 AND day LIKE '%S%'" | csvlook

#---------------------------------------------------------------------------------
# Explore Data
#---------------------------------------------------------------------------------
# to check the data types
# e.g.
csvsql iris.csv


# count num unique values
cat data/iris.csv | csvcut -c species | body "uniq | wc -l"

# show number of unique values in each column
csvstat data/iris.csv --unique

# treat as categorical value if num of unique values is far less than
#  the number of rows

# all statistics
csvstat data/iris.csv

# stat for some selected columns only
csvstat data/iris.csv -c 2,14

# explore data using R
data/iris.csv Rio -e 'summary(df)'


# Create visualization
# examples:
< data/tips.csv Rio -ge 'g+geom_histogram(aes(bill))' | display

< data/tips.csv Rio -ge 'g+geom_density(aes(tip / bill * 100, fill=sex), alpha=0.3) + xlab("percent")' | display

#---------------------------------------------------------------------------------
# Parallel Pipeline
#---------------------------------------------------------------------------------
echo "2.1^3" | bc

# command line for loop
for i in {0..100..2}; do echo "$i^2" | bc ; done

# GNU Parallel
seq 5 | parallel --no-notice "echo {}^2 | bc"

# exmaples
zcat *.json.gz | jq -r '.borough' | tr '[A-Z] ' '[a-z]_' | sort | uniq -c

#---------------------------------------------------------------------------------
# Modeling
#---------------------------------------------------------------------------------
# view multiple files

head wine-{red,white}.csv
wc -l wine-{red,white}.csv

# check missing data
csvstat wine-both-clean.csv --nulls

# install tapkee
sudo apt-get install libeigen3-dev
curl -sL https://github.com/lisitsyn/tapkee/archive/master.tar.gz > tapkee-master.tar.gz

# ERROR: eigen3 lib problems
tar -xzf tapkee-master.tar.gz
cd tapkee-master
mkdir build && cd build

#---------------------------------------------------------------------------------
# Python
#---------------------------------------------------------------------------------
# doctest
python -m doctest -v <source_file or txt_file>

# to enable interact in jupyter
pip install ipywidgets
jupyter nbextension enable --py widgetsnbextension

# bokeh server
bokeh serve eda --show --args abalone.csv

#---------------------------------------------------------------------------------
# gcc / g++
#---------------------------------------------------------------------------------
# compilation c++11
g++ -std=c++11 <file_name>


gcc -std=c99 -Wall problem3.c -lm

#---------------------------------------------------------------------
# generate debug info
gcc -g filename.c

# lib path
gcc -I <header folder>
# output executable name
gcc -o <output executable>

# generate object file
gcc -c <src file>

# to get the size of file
size <object file>

# get a list of symbols
objdump --syms <object file>

# disassemble
objdump -d <object file>


#---------------------------------------------------------------------
# to find the location of glibc shared library
ldd <executatable> | grep libc

# init file
~/.gdbinit

# TUI mode
gdb -tui <executable>


#---------------------------------------------------------------------
# gdb debug
objdump -M intel -D a.out \ grep -A20 main.:

# with debug info
gcc -g <filename>

# inside GDB:
info register (i r)

# set intel format
set disassembly-flavor intel


# display assembly code
disassemble <function>
# example:
disass main

# show content
x/i (instruction) var
x/x (hex) var 
x/d (decimal) var
x/b (binary) var
x/o (octal) var
x/s (string) var (pointer)

# examine variables
print &pointer (address)
print pointer (content)

# display value of var
p <varName>

rbp : frame pointer
rip : execution pointer
rsp : stack pointer



#---------------------------------------------------------------------
# check intstruction (5 lines) at register rip
x/5i $rip

# register rip points to the current instruction

--------------------------------------------------------------------
# javac
--------------------------------------------------------------------
On Unix, we would do this: (in colon)
javac -classpath dir1:dir2:dir3 ...

# check class path
echo $CLASSPATH

# to specify the class out directory
javac -d <class_out_dir>

######  NOTE:
#if specifying -cp in command line, this would override the
#CLASSPATH setting!


--------------------------------------------------------------------
# java
--------------------------------------------------------------------
# use -cp to specific path (if not in the global class path)
# example 1
# current path:
~/FraDir/learn/introcs/out/production/introcs$

# to run:
java -cp ./:/home/fra/FraDir/learn/introcs/stdlib-package.jar exercise.FindMinMax
# where the java class is under exercise/FindMinMax.class
# the package is called exercise

# example 2
# to compile:
javac -cp ../stdlib.jar RandomSeq.java
# to run: (need to add the current path)
java -cp ./:../stdlib.jar RandomSeq 10

--------------------------------------------------------------------
# maven
--------------------------------------------------------------------
# create folder structure:
mkdir -p src/main/java/hello

# create a pom.xml in the same folder as src

# compile
mvn compile

# install
mvn clean install


--------------------------------------------------------------------
# package
--------------------------------------------------------------------
# if the java class is part of a package
# for example in Precedence.java, it begins with the package keyword followed by the structure

package com.operators;

[parent]
	[com]
		[operators]
		
# in this case, run this command at the parent folder 
java com.operators.Precedence


# javadoc
# to create html documentation
Usage: javadoc [options] [packagenames] [sourcefiles] [@files]

--------------------------------------------------------------------
# introcs
--------------------------------------------------------------------
# with classpath set in .bashrc
# run at /home/fra/FraDir/learn/introcs/src
# Newton.java is part of the package introcs
javac introcs/Newton.java
java introcs.Newton 


--------------------------------------------------------------------
# JAR package
--------------------------------------------------------------------
# to view contents a JAR file
jar tf <jar file>

# to extract contents a JAR file
jar xf <jar file>

# to create a JAR file
jar cf <jar file> <input files>

--------------------------------------------------------------------
# Intellij setup
--------------------------------------------------------------------
javac -cp "C:\Users\m038402\Documents\myWork\Codes\algs4-master\src\main\java" .\edu\princeton\cs\algs4\ThreeSum.java

# standford NLP Core
java -cp "*" -Xmx1g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file input.txt

java -mx1g -cp "*" edu.stanford.nlp.pipeline.StanfordCoreNLPServer
http://localhost:9000/


# Think in Java
# for additional libraries, e.g. javaassist and xom, place them under a lib folder (e.g. IdeaProjects/ThinkinJava/lib)
# To import the libraries, put the lib folder in the Modeules->dependencies 

--------------------------------------------------------------------
Intellij project setup
--------------------------------------------------------------------
#  project structure
Ctrl-ALt_Shift-S

# Project:
# Check SDK : oracle
# Project level : default

# SDK
# setup SDK to the desired java version

# Modules
# setup project structure

# Modules -> Dependencies
# add external libraries here

