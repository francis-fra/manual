#-------------------------------------------------------
# Zookeeper
#-------------------------------------------------------
# download and extract binary into:
/usr/local

# create soft link
sudo ln -s zookeeper-xxx /usr/local/zookeeper

# create config file conf/zoo.cfg
tickTime=2000
dataDir=/var/zookeeper
clientPort=2181

# create data directory
mkdir /var/zookeeper

# change ownership
chown fra:hdgrp /var/zookeeper

# to start
bin/zkServer.sh start

# to check (are you ok)
telnet localhost 2181
ruok

# start CLI
bin/zkCli.sh

# to stop server
bin/zkServer.sh stop


#-------------------------------------------------------
# Hive
#-------------------------------------------------------
# download and extract binary

# copy to:
/usr/local/

# create soft link
sudo ln -s /usr/local/hive-xxxx /usr/local/hive
sudo chown -R fra:hdgrp /usr/local/hive

# edit .bashrc
export HIVE_HOME="/usr/local/hive" 
export PATH=$PATH:$HIVE_HOME/bin

export CLASSPATH=$CLASSPATH:/usr/local/hadoop/lib/*:.
export CLASSPATH=$CLASSPATH:/usr/local/hive/lib/*:.

# start Hadoop
sbin/start-dfs.sh
sbin/start-yarn.sh

# create Hive warehouse directory 
hadoop fs -mkdir /tmp
hadoop fs -mkdir /user/hive
hadoop fs -mkdir /user/hive/warehouse
hadoop fs -chmod g+w /tmp
hadoop fs -chmod g+w /user/hive/warehouse

#-------------------------------------------------------
# hive-env.sh
#-------------------------------------------------------
# edit hive-env.sh (configure Hive)
cd $HIVE_HOME/conf

# copy environment file
sudo cp hive-env.sh.template hive-env.sh

# add this line
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_HEAPSIZE=512

# multiple SLF4J: remove??
#rm lib/log4j-slf4j-impl-*.jar

# Hive CLI (deprecated)
$HIVE_HOME/bin/hive

# HiveServer2 and Beeline

#-------------------------------------------------------
# Install Derby
#-------------------------------------------------------
wget http://apache.mirror.digitalpacific.com.au//db/derby/db-derby-10.14.1.0/db-derby-10.14.1.0-bin.tar.gz
sudo tar xvzf db-derby-10.14.1.0-bin.tar.gz -C /usr/local
# create soft link
sudo ln -s /usr/local/db-derby-xxx /usr/local/derby

# edit .bashrc
export DERBY_HOME=/usr/local/derby
export PATH=$PATH:$DERBY_HOME/bin
export CLASSPATH=$CLASSPATH:$DERBY_HOME/lib/derby.jar:$DERBY_HOME/lib/derbytools.jar

# check derby status
java org.apache.derby.tools.sysinfo
# output:
--------- Derby Information --------
[/usr/local/db-derby-10.14.1.0-bin/lib/derby.jar] 10.14.1.0 - (1808820)
[/usr/local/db-derby-10.14.1.0-bin/lib/derbytools.jar] 10.14.1.0 - (1808820)
[/usr/local/apache-hive-2.3.2-bin/lib/derbynet-10.11.1.1.jar] 10.11.1.1 - (1616546)
[/usr/local/apache-hive-2.3.2-bin/lib/derbyclient-10.11.1.1.jar] 10.11.1.1 - (1616546)
[/usr/local/apache-hive-2.3.2-bin/lib/derby-10.10.2.0.jar] 10.10.2.0 - (1582446)
------------------------------------------------------

# create metastore data
mdir $DERBY_HOME/data

# set default database as Derby
schematool -initSchema -dbType derby
# output:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/apache-hive-2.3.2-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Metastore connection URL:	 jdbc:derby:;databaseName=metastore_db;create=true
Metastore Connection Driver :	 org.apache.derby.jdbc.EmbeddedDriver
Metastore connection User:	 APP
Starting metastore schema initialization to 2.3.0
Initialization script hive-schema-2.3.0.derby.sql
Initialization script completed
schemaTool completed

# if failed, run the following and try running schematool again
mv metastore_db metastore_db.tmp

# start up ij (interative SQL)
java org.apache.derby.tools.ij

#-------------------------------------------------------
# hive-site.xml
#-------------------------------------------------------
# inside $HIVE_HOME/conf
sudo cp hive-default.xml.template hive-site.xml

# make sure this is in the config file
# edit config file: (hive-site.xml)

 <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:derby:;databaseName=metastore_db;create=true</value>
    <description>
      JDBC connect string for a JDBC metastore.
      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
    </description>
  </property>

  <property>
    <name>hive.exec.local.scratchdir</name>
    <!-- <value>${system:java.io.tmpdir}/${system:user.name}</value> -->
    <value>/tmp/${system:user.name}</value>
    <description>Local scratch space for Hive jobs</description>
  </property>
  
  <property>
    <name>hive.downloaded.resources.dir</name>
    <!-- <value>${system:java.io.tmpdir}/${hive.session.id}_resources</value> -->
    <value>/tmp/${hive.session.id}_resources</value>
    <description>Temporary local directory for added resources in the remote file system.</description>
  </property>

# create a file named jpox.properties:

javax.jdo.PersistenceManagerFactoryClass =

org.jpox.PersistenceManagerFactoryImpl
org.jpox.autoCreateSchema = false
org.jpox.validateTables = false
org.jpox.validateColumns = false
org.jpox.validateConstraints = false
org.jpox.storeManagerType = rdbms
org.jpox.autoCreateSchema = true
org.jpox.autoStartMechanismMode = checked
org.jpox.transactionIsolation = read_committed
javax.jdo.option.DetachAllOnCommit = true
javax.jdo.option.NontransactionalRead = true
javax.jdo.option.ConnectionDriverName = org.apache.derby.jdbc.ClientDriver
javax.jdo.option.ConnectionURL = jdbc:derby://hadoop1:1527/metastore_db;create = true
javax.jdo.option.ConnectionUserName = APP
javax.jdo.option.ConnectionPassword = mine

#-------------------------------------------------------
# TODO: HiveServer
#-------------------------------------------------------
# FIXME: to run HiveServer2
hiveserver2
or
hive --service hiveserver2

# start beeline
beeline

# check if hiveserver2 has been started
sudo service hive-server2 status

$ $HIVE_HOME/bin/hiveserver2
$ $HIVE_HOME/bin/beeline -u jdbc:hive2://$HS2_HOST:$HS2_PORT/usr/lib

#-------------------------------------------------------
# TODO: HIVE CLI
#-------------------------------------------------------
# FIXME: not responding??
$HIVE_HOME/bin/hiveserver2
$HIVE_HOME/bin/beeline -u jdbc:hive2://localhost:10000

# HCatalog server
# need to install HCatalog first
$HIVE_HOME/hcatalog/sbin/hcat_server.sh start
$HIVE_HOME/hcatalog/sbin/hcat_server.sh stop

# FIXME: error
$HIVE_HOME/hcatalog/bin/hcat

# python database package
pip3 install pyhive --user
pip3 install psycopg2 --user
pip3 install mysqlclient --user



#-------------------------------------------------------
# Druid
#-------------------------------------------------------
# download and extract tar gzip file
curl -O http://static.druid.io/artifacts/releases/druid-0.11.0-bin.tar.gz
tar -xzf druid-0.11.0-bin.tar.gz
sudo mv druid-xxx /usr/local

sudo ln -s /usr/local/druid-xxx /usr/local/drid
sudo chown -R fra:hdgrp /usr/local/hive


# start up zookeper
/usr/local/zookeeper/bin/zkServer.sh start

# start up Druid services
bin/init

#-------------------------------------------------------
# Testing: load batch data test
#-------------------------------------------------------
java `cat conf-quickstart/druid/historical/jvm.config | xargs` -cp "conf-quickstart/druid/_common:conf-quickstart/druid/historical:lib/*" io.druid.cli.Main server historical
java `cat conf-quickstart/druid/broker/jvm.config | xargs` -cp "conf-quickstart/druid/_common:conf-quickstart/druid/broker:lib/*" io.druid.cli.Main server broker
java `cat conf-quickstart/druid/coordinator/jvm.config | xargs` -cp "conf-quickstart/druid/_common:conf-quickstart/druid/coordinator:lib/*" io.druid.cli.Main server coordinator
java `cat conf-quickstart/druid/overlord/jvm.config | xargs` -cp "conf-quickstart/druid/_common:conf-quickstart/druid/overlord:lib/*" io.druid.cli.Main server overlord
java `cat conf-quickstart/druid/middleManager/jvm.config | xargs` -cp "conf-quickstart/druid/_common:conf-quickstart/druid/middleManager:lib/*" io.druid.cli.Main server middleManager

# submit a task
curl -X 'POST' -H 'Content-Type:application/json' -d @quickstart/wikiticker-index.json localhost:8090/druid/indexer/v1/task


#-------------------------------------------------------
# Testing: load streaming data test
#-------------------------------------------------------
# download tranquility library
curl -O http://static.druid.io/tranquility/releases/tranquility-distribution-0.8.0.tgz
tar -xzf tranquility-distribution-0.8.0.tgz
cd tranquility-distribution-0.8.0

# move to /usr/local
bin/tranquility server -configFile /usr/local/druid/conf-quickstart/tranquility/server.json

bin/generate-example-metrics | curl -XPOST -H'Content-Type: application/json' --data-binary @- http://localhost:8200/v1/post/metrics

# TODO: druid console
http://localhost:8090/console.html.

#-------------------------------------------------------
# Superset
#-------------------------------------------------------
# prerequisite
sudo apt-get install build-essential libssl-dev libffi-dev python-dev python-pip libsasl2-dev libldap2-dev

pip3 install superset --user

# create credential
fabmanager create-admin --app superset

# init database
superset db upgrade

# Load some data to play with
superset load_examples

# Create default roles and permissions
superset init

# Start the web server on port 8088, use -p to bind to another port
superset runserver -p 8099

#-------------------------------------------------------
# Metabase
#-------------------------------------------------------
java -jar metabase.jar

http://localhost:3000 


#-------------------------------------------------------
# FIXME: Ambari
#-------------------------------------------------------
# download and extract tarballs

# compile the source
cd apache-ambari-2.6.0-src
mvn versions:set -DnewVersion=2.6.0.0.0

pushd ambari-metrics
mvn versions:set -DnewVersion=2.6.0.0.0
popd

mvn -B clean install package jdeb:jdeb -DnewVersion=2.6.0.0.0 -DskipTests -Dpython.ver="python >= 2.6"
# To fix compile error: change version number from storm-1.1.0-SNAPSHOT to storm-1.1.0 in pom.xml

# add these to pom.xml if errors are found:
+      <plugin>
+        <groupId>org.vafer</groupId>
+        <artifactId>jdeb</artifactId>
+        <version>1.0.1</version>
+        <executions>
+          <execution>
+            <!--Stub execution on direct plugin call - workaround for ambari deb build process-->
+            <id>stub-execution</id>
+            <phase>none</phase>
+            <goals>
+              <goal>jdeb</goal>
+            </goals>
+          </execution>
+        </executions>
+        <configuration>
+          <skip>true</skip>
+          <attach>false</attach>
+          <submodules>false</submodules>
+          <controlDir>${project.basedir}/../src/main/package/deb/control</controlDir>
+        </configuration>
+      </plugin>

# install ambari server
cd ./ambari-server/target
sudo apt-get install ./ambari-server*.deb

# login as root
su
export buildNumber=2.6.0.0
ambari-server setup
ambari-server start

# install ambari agent
cd ./ambari-agent/target
sudo apt-get install ./ambari-agent*.deb

# Edit /etc/ambari-agent/ambari.ini
[server]
hostname=localhost

ambari-agent start

# web UI:
localhost:8080.

# start ambari agent
ambari-agent start

# login / password: admin

#-------------------------------------------------------
# HBase
#-------------------------------------------------------
# download and extract tarballs

sudo ln -s /usr/local/hbase-xxx /usr/local/hbase

sudo chown fra:hdgrp -R /usr/local/hbase

# edit .bashrc
export HBASE_HOME=/usr/local/hbase
export PATH=$PATH:$HBASE_HOME/bin

# edit /usr/local/hbase/conf/hbase-env.sh
export JAVA_HOME=/usr/java/latest
export HBASE_SSH_OPTS="-p 2882"


# edit hbase-site.xml
# the port 8088 must be matched with the hadoop hdfs port
<configuration>

     <property>
      <name>hbase.rootdir</name>
      <value>hdfs://localhost:9000/hbase</value>
     </property>

     <property>
       <name>hbase.cluster.distributed</name>
       <value>true</value>
     </property>

</configuration>

# starting hbase
/usr/local/Hbase/bin/start-hbase.sh
# stop hbase
bin/stop-hbase.sh

# start hadoop and hbase
start-dfs.sh
start-yarn.sh
start-hbase.sh

# check directory
hdfs dfs -ls /hbase

# must start zookeeper first
zkServer.sh start

# shell CLI
hbase shell

# UI??
http://localhost:16010/


#-------------------------------------------------------
# Kafka
#-------------------------------------------------------
# download and extract tarzip

# create soft link
sudo ln -s kafka_2.12-0.11.0.1/ /usr/local/kafka

sudo chown -R fra:hdgrp kafka

# config kafka server
# edit ~/kafka/config/server.properties:

# uncomment the following:
delete.topic.enable=true

# start kafka server
kafka-server-start.sh ~/kafka/config/server.properties
nohup ~/kafka/bin/kafka-server-start.sh ~/kafka/config/server.properties

# check
netstat -nlpt
jps

# to stop
../bin/kafka-server-stop.sh config/server.properties

# create topic
./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
# check 
./bin/kafka-topics.sh --list --zookeeper localhost:2181

# send some message
./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
(type some message)

# start a consumer
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

# to send
echo "Hello, World" | ~/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic TutorialTopic > /dev/null
# to receive
./bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic TutorialTopic --from-beginning

# kafka python
sudo pip install kafka-python

#-------------------------------------------------------
# TODO: Cassandra
#-------------------------------------------------------
# install debian package
# add repository
echo "deb http://www.apache.org/dist/cassandra/debian 311x main" | sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list
# add repository key
curl https://www.apache.org/dist/cassandra/KEYS | sudo apt-key add -
# update
sudo apt-get update
# add public key is there is an error
sudo apt-key adv --keyserver pool.sks-keyservers.net --recv-key A278B781FE4B2BDA

# install
sudo apt-get install cassandra

# check cassandra
sudo service cassandra status

nodetool status

# location:
/etc/cassandra


#-------------------------------------------------------
# TODO: Avro
#-------------------------------------------------------


#-------------------------------------------------------
# TODO: Phoenix
#-------------------------------------------------------



#-------------------------------------------------------
# Pig
#-------------------------------------------------------
# download and extract tar zip file

# create soft link
sudo ln -s /usr/local/pig-xxxx /usr/local/pig

# change ownership
sudo chown -R fra:hdgrp /usr/local/pig


# edit .bashrc
export PIG_HOME=/usr/local/pig
export PATH=$PATH:/usr/local/pig/bin
export PIG_CLASSPATH=$HADOOP_HOME/etc/hadoop

# run command
pig -version
# local mode
pig -x local
pig


#-------------------------------------------------------
# Zeppelin
#-------------------------------------------------------
# download and extract binary into:

# create soft link
sudo ln -s zeppelin-0.7.3-bin-netinst/ /usr/local/zeppelin

# change ownership
sudo chown -R fra:hdgrp /usr/local/zeppelin

# to start
sudo bin/zeppelin-daemon.sh start

# link:
http://localhost:8080/

# start with a service manager
#---------------------------------------------------------------
# optional: create new file /etc/init/zeppelin.conf
#---------------------------------------------------------------
description "zeppelin"

start on (local-filesystems and net-device-up IFACE!=lo)
stop on shutdown

# Respawn the process on unexpected termination
respawn

# respawn the job up to 7 times within a 5 second period.
# If the job exceeds these values, it will be stopped and marked as failed.
respawn limit 7 5

# zeppelin was installed in /usr/local/zeppelin in this example
chdir /usr/local/zeppelin
exec bin/zeppelin-daemon.sh upstart

#---------------------------------------------------------------
# list all interpreters:
./bin/install-interpreter.sh --list

# install interpreters:
sudo ./bin/install-interpreter.sh --name shell,python

# optional: to create credential
cp conf/shiro.ini.template shiro.ini

# make sure this line is commented to prevent anonymous login
#/** = anon

# login and passwords are listed in [users] section




#-------------------------------------------------------
# Storm
#-------------------------------------------------------
# download and extract tar ball

# create soft link
sudo ln -s /usr/local/apache-storm-xxxx /usr/local/storm

# create data directory
mkdir /var/storm

# change ownership
chown fra:hdgrp /var/storm

# edit conf/storm.yaml
storm.zookeeper.servers:
 - "localhost"
storm.local.dir: “/var/storm”
nimbus.host: "localhost"
supervisor.slots.ports:
 - 6700
 - 6701
 - 6702
 - 6703


# start zookeeper
/usr/local/zookeeper/bin/zkServer.sh start

# start nimbus
bin/storm nimbus

# start supervisor
bin/storm supervisor

# start UI
/bin/storm ui

http://localhost:8080




